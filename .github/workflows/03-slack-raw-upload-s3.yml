name: 03 - Slack Raw Data Upload to S3
description: |
  This workflow uploads raw Slack data to S3 using the Slack API.
  It runs on a schedule or can be triggered manually.

on:
  workflow_dispatch:

  # run on push
#  push:
#      branches:
#        - data-ingestion
  schedule:
     - cron: "45 5 * * *"  # Daily at 11:15 AM IST (5:45 AM UTC)

env:
  # AWS Configuration
  BUCKET_DATA: ${{ vars.BUCKET_DATA }}
  AWS_REGION: ${{ vars.AWS_REGION }}
  AWS_ACCOUNT_ID: ${{ vars.AWS_ACCOUNT_ID }}
  SLACK_S3_WRITER_ROLE_NAME: ${{ vars.SLACK_S3_WRITER_ROLE_NAME }}
  
  # Pipeline Configuration
  WINDOW_HOURS: ${{ vars.WINDOW_HOURS }}
  S3_SSE: ${{ vars.S3_SSE }}
  S3_SSE_KMS_KEY_ID: ${{ vars.S3_SSE_KMS_KEY_ID }}
  S3_WRITE_ATOMIC: ${{ vars.S3_WRITE_ATOMIC }}
  S3_WRITE_SHA256: ${{ vars.S3_WRITE_SHA256 }}
  RATE_JITTER_MS: ${{ vars.RATE_JITTER_MS }}
  RATE_MAX_BACKOFF_S: ${{ vars.RATE_MAX_BACKOFF_S }}
  
  # Slack Channel IDs
  SLACK_CHANNEL_DATA_ENGINEERING: ${{ vars.SLACK_CHANNEL_DATA_ENGINEERING }}
  SLACK_CHANNEL_LLM_ZOOMCAMP: ${{ vars.SLACK_CHANNEL_LLM_ZOOMCAMP }}
  SLACK_CHANNEL_MLOPS_ZOOMCAMP: ${{ vars.SLACK_CHANNEL_MLOPS_ZOOMCAMP }}
  SLACK_CHANNEL_ML_ZOOMCAMP: ${{ vars.SLACK_CHANNEL_ML_ZOOMCAMP }}
  SLACK_CHANNEL_STOCKS_ANALYTICS: ${{ vars.SLACK_CHANNEL_STOCKS_ANALYTICS }}

jobs:
  slack-to-s3:
    name: Upload Slack Raw Data to S3
    runs-on: ubuntu-latest
    environment: dev
    
    permissions:
      id-token: write
      contents: read
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup uv
        uses: astral-sh/setup-uv@v3
      
      - name: Install dependencies
        run: uv sync --group ingest
      
      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ env.AWS_ACCOUNT_ID }}:role/${{ env.SLACK_S3_WRITER_ROLE_NAME }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Verify AWS Identity
        run: |
          echo "Current AWS identity:"
          aws sts get-caller-identity
      
      - name: Run Slack to S3 Raw Data Pipeline
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
        run: |
          echo "Starting Slack data ingestion..."
          echo "Window: ${{ env.WINDOW_HOURS }} hours"
          echo "Target bucket: ${{ env.BUCKET_DATA }}"
          uv run python data-ingestion/pipeline/slack_api_to_s3_raw.py
      
      - name: Output Summary
        if: always()
        run: |
          echo "## Slack Raw Data Upload Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **Window**: ${{ env.WINDOW_HOURS }} hours" >> $GITHUB_STEP_SUMMARY
          echo "- **Bucket**: ${{ env.BUCKET_DATA }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Region**: ${{ env.AWS_REGION }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY